{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1\n",
    "\n",
    "Output = w1 * x1 + w2 * x2\n",
    "Where in my case w1 = -0.26 and w2 = -0.43, and that looks accurate to the line shown.\n",
    "\n",
    "### #2\n",
    "\n",
    "after epoch 1 w1 = 0.38, and w2 = .18, the test loss is 0.030, training loss is 0.030\n",
    "epoch 2: 0.44, 0.26, 0.014, 0.014\n",
    "\n",
    "### #3\n",
    "\n",
    "After a few hundred epochs the weights both became 1.0, so our equation is just Output = x1 + x2\n",
    "\n",
    "### #4 \n",
    "\n",
    "The initial weights are -0.11, and 0.36, after one epoch they go to 0.14, 0.53, and the loass is at 0.022.\n",
    "After a few hundred epochs w1 and w2 normalize to 1, but it did seem to take longer than the linear activation to get there, which is to be expected when the data is linear.\n",
    "\n",
    "### #5 \n",
    "\n",
    "I notice that the weights got to w1 = 1.0 and w2 = 1.4, and the loss never go to 0.0 like it did previously, as some of the data is miscategorized.\n",
    "\n",
    "### #6\n",
    "\n",
    "The other data sets do very poorly and can't categorize the data at all. \n",
    "\n",
    "### #7\n",
    "\n",
    "The single neuron represents a linear boundary for decisions in the classification problems. It takes the weights inputs, applies an activation function and produces an output, to then have the weights adjusted and repeat the process.\n",
    "\n",
    "### #8\n",
    "\n",
    "No, because XNOR is not linearly separable, there isnt a straight line that can separate the 2 classes. we need at least 1 hidden layer with multiple neurons. \n",
    "\n",
    "### #9\n",
    "\n",
    "No, for similar reason as the XNOR example, 1 neuron suggests a linearly separable data set, and the circle is not of such case.\n",
    "\n",
    "### #10 \n",
    "\n",
    "Again, no, this data set is far too complex for a linear model to correctly classify.\n",
    "\n",
    "### #11\n",
    "\n",
    "We learned that a single neuron can only create a linear decision boundary, meaning it can only classify data that is linearly separable. However real world data is often much more complicated than that. We use multiple neurons in hidden layers to transform the input space, applying nonlinear activation functons like ReLu for example so the network can learn more complex situations. Stacking multiple layers to extract high level features.\n",
    "\n",
    "### #12\n",
    "\n",
    "As I added a hidden layer with 1 neuron, the model still struggled with the XNOR classification due to insufficient complexity. With 2 neurons, the performance improved slightly, reducing the loss to 0.250, but it was still not optimal. At 3 neurons, the network was finally able to learn the nonlinear decision boundary effectively, achieving a loss below 0.05, demonstrating that increasing neurons allows the model to better capture complex patterns.\n",
    "\n",
    "### #13\n",
    "\n",
    "I spent some time playing with the spiral dataset as it seemed the most complex. I was able to get a really good classification using 2 hidden layers both with 4 neurons. and an activation of ReLU\n",
    "and then using x1, x2, x2^2, x1^2, and x1x2, gave me a loss of <0.1 pretty quickly, increasing neurons and hidden layers gave me similar results but just took way longer. Also i noticed if i let the simulation run for a very long time >5,000 epochs it just really bad and started to just essentially guess. \n",
    "\n",
    "### #14\n",
    "\n",
    "I would be really interested in adjusting the learning rate, so far i have done everything at 0.03, and would like to see the convergence speed and final loss at different rates.\n",
    "Also to see if too many hidden layers is bad, does it always improve model performance, i have a hunch that at some point there are diminishing returns but do the returns at some point get worse?\n",
    "\n",
    "### #15\n",
    "\n",
    "This slider adjusts how many data points are in the testing and training data. If you include more data to be tested on, typically the model will be more robust but could be more prone to misclassification on the test data. the range is from 10% to 90%. I think its about understanding your problem and seeing what works for your situation.\n",
    "\n",
    "### #16\n",
    "\n",
    "The noise introduces -1 values in the space where +1 values are, and vise-versa, this will inevitably lead to more missclassifications, but is more realistic to the real world. You could theoretically have the exact same data points but with different outcomes in the real world due to maybe a variable you arent taking into account or just pure chance.\n",
    "\n",
    "### #17 \n",
    "\n",
    "The batch size determines how many samples are processed before updating the model's weights. smaller batches will update more frequently and could be more spiratic and have higher variance, and a larger batch size will be slower but more stable on average.\n",
    "\n",
    "### #18 \n",
    "\n",
    "It looks like it resets the model and adds different starting weights.\n",
    "\n",
    "### #19\n",
    "\n",
    "You could see the effects of the batch size on simple vs complex models, same with the noise, does having more noise affect the spiral model or the linear model more? I dont think its so clear, a lot of noise in the linear model could actually be more detrimental than a hidden layer model that is more robust, but the complex model might try to do too much and mis classify the easy points.\n",
    "\n",
    "### #20\n",
    "\n",
    "I Already work full time as a software / data engineer and I plan on reiterating some things from this class and from Tinker to my coworkers as it is quite interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluating Learning Algorithms in Neural Networks\n",
    "\n",
    "When working with neural networks, it is crucial to evaluate how well an algorithm is performing beyond just looking at training accuracy. A well-performing model should generalize to unseen data rather than just memorizing the training set. This evaluation involves splitting data into training and test sets to measure both training performance and generalization ability. If a model achieves high accuracy on the training set but struggles with new data, it indicates overfitting, whereas consistently poor accuracy across both suggests underfitting. A good neural network should strike a balance, learning from training data while still performing well on unseen examples. Evaluating models properly ensures that we select an architecture and training setup that not only works in a controlled setting but also in real-world scenarios.\n",
    "\n",
    "- Evaluating Hypotheses in Neural Networks\n",
    "\n",
    "Neural networks are fundamentally hypothesis-driven, meaning they attempt to approximate a function that maps input data to desired outputs. To evaluate different hypotheses, we must measure how well our model approximates the true function using training and test data. A well-trained network should minimize the difference between predicted and actual values, typically measured through loss functions such as cross-entropy for classification or mean squared error for regression. However, measuring performance extends beyond accuracy; precision, recall, and F1-score help analyze cases where false positives and false negatives carry different costs. Additionally, models must be tested on data they haven’t seen before, as memorizing training data does not imply a robust hypothesis. By carefully evaluating hypotheses, we ensure that our network is making informed, generalizable predictions rather than simply memorizing patterns.\n",
    "\n",
    "- Model Selection and Test Sets in Neural Networks\n",
    "\n",
    "Choosing the right neural network architecture involves balancing complexity and performance. Model selection requires comparing different configurations, such as varying the number of layers, neurons per layer, and activation functions. A key part of this process is using test and validation sets—the test set evaluates the final model’s performance, while the validation set helps fine-tune hyperparameters during training. Without a validation set, there's a risk of overfitting to the training data, leading to poor generalization. Cross-validation techniques further help in selecting models by testing performance across different data splits. Ultimately, model selection should be based on a combination of empirical results, theoretical considerations, and an understanding of the data's complexity.\n",
    "\n",
    "- Diagnosing Bias and Variance in Neural Networks\n",
    "\n",
    "One of the fundamental challenges in neural network training is the bias-variance tradeoff. A model with high bias makes strong assumptions about the data and may be too simplistic, leading to underfitting. On the other hand, a model with high variance is overly complex, capturing noise in the training data and leading to overfitting. To diagnose these issues, we compare training and test loss: if both are high, the model has high bias, while a low training loss but high test loss suggests high variance. Addressing bias requires increasing model complexity, using deeper networks, or incorporating non-linear features. Reducing variance, on the other hand, can be done using regularization, increasing training data, or applying dropout techniques. Proper diagnosis helps guide corrective actions to improve generalization.\n",
    "\n",
    "- Regularization and the Bias-Variance Tradeoff\n",
    "\n",
    "Regularization techniques such as L1 (Lasso) and L2 (Ridge) regularization help prevent overfitting by penalizing large weight values, effectively simplifying the model. Dropout is another technique where neurons are randomly ignored during training, forcing the network to learn more generalized features. Regularization does not just reduce variance but can also introduce a small amount of bias, though this is often a beneficial tradeoff. By carefully adjusting regularization strength, we can find an optimal balance where the model is neither too simple nor too complex, ensuring strong generalization while maintaining predictive power.\n",
    "\n",
    "- Learning Curves and Their Role in Model Diagnosis\n",
    "\n",
    "Learning curves are an essential tool for understanding a model’s performance over time. A learning curve plots training and validation loss against the number of epochs, helping diagnose underfitting, overfitting, and whether more training data is needed. If both losses remain high, the model is underfitting and may require more complexity. If the training loss is low but the validation loss remains high, the model is overfitting, suggesting the need for more data or regularization. In some cases, learning curves plateau early, indicating the learning rate may be too high. By analyzing these trends, we can make informed adjustments to the network, improving its overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG DATA Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12811 entries, 0 to 12810\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SubjectID           12811 non-null  float64\n",
      " 1   VideoID             12811 non-null  float64\n",
      " 2   Attention           12811 non-null  float64\n",
      " 3   Mediation           12811 non-null  float64\n",
      " 4   Raw                 12811 non-null  float64\n",
      " 5   Delta               12811 non-null  float64\n",
      " 6   Theta               12811 non-null  float64\n",
      " 7   Alpha1              12811 non-null  float64\n",
      " 8   Alpha2              12811 non-null  float64\n",
      " 9   Beta1               12811 non-null  float64\n",
      " 10  Beta2               12811 non-null  float64\n",
      " 11  Gamma1              12811 non-null  float64\n",
      " 12  Gamma2              12811 non-null  float64\n",
      " 13  predefinedlabel     12811 non-null  float64\n",
      " 14  user-definedlabeln  12811 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "   SubjectID  VideoID  Attention  Mediation    Raw      Delta     Theta  \\\n",
      "0        0.0      0.0       56.0       43.0  278.0   301963.0   90612.0   \n",
      "1        0.0      0.0       40.0       35.0  -50.0    73787.0   28083.0   \n",
      "2        0.0      0.0       47.0       48.0  101.0   758353.0  383745.0   \n",
      "3        0.0      0.0       47.0       57.0   -5.0  2012240.0  129350.0   \n",
      "4        0.0      0.0       44.0       53.0   -8.0  1005145.0  354328.0   \n",
      "\n",
      "     Alpha1   Alpha2    Beta1     Beta2   Gamma1   Gamma2  predefinedlabel  \\\n",
      "0   33735.0  23991.0  27946.0   45097.0  33228.0   8293.0              0.0   \n",
      "1    1439.0   2240.0   2746.0    3687.0   5293.0   2740.0              0.0   \n",
      "2  201999.0  62107.0  36293.0  130536.0  57243.0  25354.0              0.0   \n",
      "3   61236.0  17084.0  11488.0   62462.0  49960.0  33932.0              0.0   \n",
      "4   37102.0  88881.0  45307.0   99603.0  44790.0  29749.0              0.0   \n",
      "\n",
      "   user-definedlabeln  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load EEG data\n",
    "df = pd.read_csv(\"EEG_data.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "The dataset contains 15 columns, including:\n",
    "\n",
    "- SubjectID: The unique identifier for each subject.\n",
    "- VideoID: Identifies the video the subject watched.\n",
    "- EEG Features: Includes Attention, Mediation, Raw signal, and multiple frequency bands (Delta, Theta, Alpha1, Alpha2, Beta1, Beta2, Gamma1, Gamma2).\n",
    "- Labels: The dataset provides two possible labels:\n",
    "\n",
    "  - predefinedlabel: System-generated labels based on brain activity.\n",
    "\n",
    "  - user-definedlabeln: User-defined labels.\n",
    "\n",
    "we use predefinedlabel as the target variable.\n",
    "\n",
    "Since the target variable represents discrete classes, this is a classification problem, not regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1326\n",
      "         1.0       1.00      1.00      1.00      1237\n",
      "\n",
      "    accuracy                           1.00      2563\n",
      "   macro avg       1.00      1.00      1.00      2563\n",
      "weighted avg       1.00      1.00      1.00      2563\n",
      "\n",
      "Epoch [1/20], Loss: 0.3194\n",
      "Epoch [2/20], Loss: 0.3142\n",
      "Epoch [3/20], Loss: 0.3133\n",
      "Epoch [4/20], Loss: 0.3136\n",
      "Epoch [5/20], Loss: 0.3133\n",
      "Epoch [6/20], Loss: 0.3134\n",
      "Epoch [7/20], Loss: 0.3134\n",
      "Epoch [8/20], Loss: 0.3133\n",
      "Epoch [9/20], Loss: 0.3133\n",
      "Epoch [10/20], Loss: 0.3134\n",
      "Epoch [11/20], Loss: 0.3133\n",
      "Epoch [12/20], Loss: 0.3133\n",
      "Epoch [13/20], Loss: 0.3133\n",
      "Epoch [14/20], Loss: 0.3133\n",
      "Epoch [15/20], Loss: 0.3133\n",
      "Epoch [16/20], Loss: 0.3133\n",
      "Epoch [17/20], Loss: 0.3133\n",
      "Epoch [18/20], Loss: 0.3133\n",
      "Epoch [19/20], Loss: 0.3133\n",
      "Epoch [20/20], Loss: 0.3133\n",
      "Neural Network Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1326\n",
      "           1       1.00      1.00      1.00      1237\n",
      "\n",
      "    accuracy                           1.00      2563\n",
      "   macro avg       1.00      1.00      1.00      2563\n",
      "weighted avg       1.00      1.00      1.00      2563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"predefinedlabel\", \"user-definedlabeln\", \"SubjectID\"])\n",
    "y = df[\"predefinedlabel\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Logistic Regression Performance\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Convert data for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Neural Network Model\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)  # Assuming binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "model = EEGClassifier(input_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data into DataLoader format\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Train Neural Network\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate Neural Network\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_nn = model(X_test_tensor)\n",
    "    y_pred_nn = torch.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "# Neural Network Performance\n",
    "print(\"Neural Network Performance:\")\n",
    "print(classification_report(y_test_tensor.numpy(), y_pred_nn.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Baseline Model Performance**\n",
      "Neural Network Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1326\n",
      "           1       1.00      1.00      1.00      1237\n",
      "\n",
      "    accuracy                           1.00      2563\n",
      "   macro avg       1.00      1.00      1.00      2563\n",
      "weighted avg       1.00      1.00      1.00      2563\n",
      "\n",
      "\n",
      "**After Removing Outliers**\n",
      "Neural Network Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1326\n",
      "           1       0.99      1.00      1.00      1237\n",
      "\n",
      "    accuracy                           1.00      2563\n",
      "   macro avg       1.00      1.00      1.00      2563\n",
      "weighted avg       1.00      1.00      1.00      2563\n",
      "\n",
      "\n",
      "**After Feature Selection**\n",
      "Neural Network Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1326\n",
      "           1       1.00      1.00      1.00      1237\n",
      "\n",
      "    accuracy                           1.00      2563\n",
      "   macro avg       1.00      1.00      1.00      2563\n",
      "weighted avg       1.00      1.00      1.00      2563\n",
      "\n",
      "\n",
      "**Subset of SubjectIDs**\n",
      "Neural Network Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       696\n",
      "           1       1.00      1.00      1.00       595\n",
      "\n",
      "    accuracy                           1.00      1291\n",
      "   macro avg       1.00      1.00      1.00      1291\n",
      "weighted avg       1.00      1.00      1.00      1291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# 1. Normalization (Already applied above using StandardScaler)\n",
    "# This ensures that all features have a mean of 0 and variance of 1\n",
    "\n",
    "# 2. Eliminating Outliers Using Z-score\n",
    "z_scores = np.abs(zscore(X_train))  # Compute Z-scores for all features\n",
    "# Keep rows within 3 standard deviations\n",
    "X_train_no_outliers = X_train[(z_scores < 3).all(axis=1)]\n",
    "# Keep corresponding labels\n",
    "y_train_no_outliers = y_train.loc[X_train_no_outliers.index]\n",
    "\n",
    "# Normalize again after removing outliers\n",
    "X_train_scaled_no_outliers = scaler.fit_transform(X_train_no_outliers)\n",
    "X_test_scaled_no_outliers = scaler.transform(X_test)\n",
    "\n",
    "# 3. Feature Selection (Keep Top K Features with Best Information Gain)\n",
    "# Select top 8 most relevant features\n",
    "selector = SelectKBest(score_func=f_classif, k=8)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# 4. Selecting a Subset of SubjectIDs\n",
    "# Select first 5 subjects for training\n",
    "subset_subjects = df[\"SubjectID\"].unique()[:5]\n",
    "df_subset = df[df[\"SubjectID\"].isin(subset_subjects)]\n",
    "X_subset = df_subset.drop(\n",
    "    columns=[\"predefinedlabel\", \"user-definedlabeln\", \"SubjectID\"])\n",
    "y_subset = df_subset[\"predefinedlabel\"]\n",
    "\n",
    "# Train-Test split for Subject Subset\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
    "    X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize Subject Subset\n",
    "X_train_sub_scaled = scaler.fit_transform(X_train_sub)\n",
    "X_test_sub_scaled = scaler.transform(X_test_sub)\n",
    "\n",
    "# Convert Data for PyTorch (for all scenarios)\n",
    "X_train_no_outliers_tensor = torch.tensor(\n",
    "    X_train_scaled_no_outliers, dtype=torch.float32)\n",
    "X_test_no_outliers_tensor = torch.tensor(\n",
    "    X_test_scaled_no_outliers, dtype=torch.float32)\n",
    "y_train_no_outliers_tensor = torch.tensor(\n",
    "    y_train_no_outliers.values, dtype=torch.long)\n",
    "\n",
    "X_train_selected_tensor = torch.tensor(X_train_selected, dtype=torch.float32)\n",
    "X_test_selected_tensor = torch.tensor(X_test_selected, dtype=torch.float32)\n",
    "\n",
    "X_train_sub_tensor = torch.tensor(X_train_sub_scaled, dtype=torch.float32)\n",
    "X_test_sub_tensor = torch.tensor(X_test_sub_scaled, dtype=torch.float32)\n",
    "y_train_sub_tensor = torch.tensor(y_train_sub.values, dtype=torch.long)\n",
    "y_test_sub_tensor = torch.tensor(y_test_sub.values, dtype=torch.long)\n",
    "\n",
    "# Re-train Neural Network on Each Feature Engineering Approach\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, input_size):\n",
    "    model = EEGClassifier(input_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Train model\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_nn = model(X_test_tensor)\n",
    "        y_pred_nn = torch.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "    print(\"Neural Network Performance:\")\n",
    "    print(classification_report(y_test_tensor.numpy(), y_pred_nn.numpy()))\n",
    "\n",
    "\n",
    "# Evaluate Models for Different Feature Engineering Approaches\n",
    "print(\"**Baseline Model Performance**\")\n",
    "train_and_evaluate_nn(X_train_tensor, X_test_tensor,\n",
    "                      y_train_tensor, y_test_tensor, X_train.shape[1])\n",
    "\n",
    "print(\"\\n**After Removing Outliers**\")\n",
    "train_and_evaluate_nn(X_train_no_outliers_tensor, X_test_no_outliers_tensor,\n",
    "                      y_train_no_outliers_tensor, y_test_tensor, X_train.shape[1])\n",
    "\n",
    "print(\"\\n**After Feature Selection**\")\n",
    "train_and_evaluate_nn(X_train_selected_tensor, X_test_selected_tensor,\n",
    "                      y_train_tensor, y_test_tensor, X_train_selected.shape[1])\n",
    "\n",
    "print(\"\\n**Subset of SubjectIDs**\")\n",
    "train_and_evaluate_nn(X_train_sub_tensor, X_test_sub_tensor,\n",
    "                      y_train_sub_tensor, y_test_sub_tensor, X_train_sub.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
